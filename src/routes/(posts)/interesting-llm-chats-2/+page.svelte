<svelte:head>
	<title>My chats with LLMs</title>
</svelte:head>
<h1>My chats with LLMs</h1>
<div class="opacity-60 mb-8">December 2024</div>
<p>
	I spend maybe 15% of my waking hours talking to LLMs, and I don't think that's uncommon in the Bay
	Area, but almost none of these conversations are ever shared on the internet.
</p>
<p>
	I think there's unique value in sharing chats; it's one of the best windows into your brain.
	Almost all the content you'd publish otherwise (interviews, blog posts, books) are about topics
	you're expert in, or at least have thought a lot about. Chat threads are more often about topics
	you know nothing about, making them much more vulnerable.
</p>
<p>
	I'm also interested in learning how my usage patterns differ from others'. Many people I've spoken
	to have said things like "I don't use LLMs for learning because I don't trust them. They
	hallucinate with confidence." I have personally never had an issue with hallucinations, even when
	ChatGPT first launched, and I think it's because of the way that I use LLMs. I don't care for
	citations, and I'm generally not looking for high confidence of any particular fact. LLMs are
	their own type of source. They've seen a lot of patterns in the world, and I just want them to
	show me the patterns.
</p>
<p>
	This evidently differs from how my cofounder Axel uses LLMs. He uses LLMs strictly on thinking
	mode, because he's always willing to wait longer for a more correct answer. I find this
	mind-boggling. Partly because I don't have the patience to wait 30 seconds for an answer, but also
	because for the purposes I use LLMs for, thinking usually makes the answer less useful for me. It
	causes the LLM to stray further from regurgitating what it's seen. I want the regurgitation, I
	want a statistical sense of what most experts would say.
</p>
<p>
	You probably need a sample of questions I ask to make sense of that, so here it is. This is a very
	filtered down sample, as I wouldn't want to share most of them, but it is representative of my
	general style.
</p>
<p>
	<a target="_blank" href="https://claude.ai/share/b062c73a-7bb4-48d2-a173-f8f9fbf8c523"
		>Music taste</a
	>
</p>
<p>
	<a target="_blank" href="https://chatgpt.com/share/692d0d3d-4c10-8002-a793-698580eef72c"
		>Fashion and status</a
	>
</p>
<p>
	<a target="_blank" href="https://chatgpt.com/share/69348267-7518-8002-bb3a-e2f9f8557ee8"
		>The business of wealth symbols</a
	>
</p>
<p>
	<a target="_blank" href="https://chatgpt.com/share/692d0e56-4bf0-8002-b4ef-936f1264dc10"
		>The US's entrepreneurial origins and our founding fathers</a
	>
</p>
<p>More random, but were interesting to me at points in time:</p>
<p>
	<a target="_blank" href="https://chatgpt.com/share/69348276-75d4-8002-8bf8-586b862562d3"
		>The business of renting tanks</a
	>
</p>
<p>
	<a target="_blank" href="https://claude.ai/share/d01e47e1-19df-4fd9-97dc-8b232213590f"
		>Cat with strong AI</a
	>
</p>
<p>
	<a target="_blank" href="https://claude.ai/chat/7de86710-a56d-4783-ab32-2f6500d6c6f1"
		>Social media frustration</a
	>
</p>
<p>
	<a target="_blank" href="https://claude.ai/share/9f45d613-71a4-440b-88b8-a3f1c9a78ec8"
		>SF Twitter and irony</a
	>
</p>
<p>
	<a target="_blank" href="https://claude.ai/share/6e2f765a-4189-45a6-acd2-4e74465292b1"
		>The value of vacations</a
	>
</p>
<p>
	<a target="_blank" href="https://claude.ai/share/f18c565d-a145-4d6c-aaaa-6d41380a3685"
		>On the merit of sandbagging</a
	>
</p>
<p>
	There's also plenty of chats where I make LLMs do some grunt work for me, such as trying to find
	an obscure
	<a target="_blank" href="https://chatgpt.com/share/69348253-88d8-8002-9e07-5fead3e8fbfc"
		>Feynman quote</a
	>
	I had once heard.
</p>
<p>Most of those chats need too much context to make sense of though.</p>
<hr />
<p>Some more thoughts I've formed after collecting this list:</p>
<ul>
	<li>
		<p>
			I use Claude much more for advice in social situations. It seems to have much better EQ, which
			I hear is largely due to post-training on Amanda Askell. For example,
			<a target="_blank" href="https://claude.ai/share/b9065409-c15f-4e7b-99d3-1fdf352aa448"
				>Claude</a
			>
			has a very different answer than
			<a target="_blank" href="https://chatgpt.com/share/69348426-c808-8002-a47f-b43a3e3f621a"
				>ChatGPT</a
			>
			for "Do women on average enjoy talking about agi timelines at parties less than men do?". (This
			may be in part because Askell herself hates talking about AGI at parties.)
		</p>
	</li>
	<li>
		<p>
			I also know several people that leave the memory feature of ChatGPT on. I can't imagine doing
			this myself. I'm constantly lying to GPT to test how it responds with different assumptions,
			and I also have some anti-bias techniques that depend on a clean context each chat, such as
			<a target="_blank" href="https://claude.ai/share/b942234d-5458-4e81-9269-5edf39464606"
				>flipping a loaded question</a
			>. I would use memory if I could enable it only for particular projects, but this capability
			doesn't seem to exist yet.
		</p>
	</li>
	<li>
		<p>
			I don't do any fancy prompt engineering techniques besides de-biasing techniques like above.
			Ever since RLHF, I don't think things like priming are actually useful for Q+A, though they're
			probably useful for agentic workflows.
		</p>
	</li>
</ul>
